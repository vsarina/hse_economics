{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RYp0bXOFK-hP"
   },
   "source": [
    "# Машинное обучение, ФКН ВШЭ\n",
    "\n",
    "## Практическое задание 8. Метод опорных векторов и аппроксимация ядер\n",
    "\n",
    "### Общая информация\n",
    "\n",
    "Дата выдачи: 04.02.2023\n",
    "\n",
    "Мягкий дедлайн: 23:59MSK 20.02.2023\n",
    "\n",
    "Жесткий дедлайн: 23:59MSK 26.02.2023\n",
    "\n",
    "### Оценивание и штрафы\n",
    "Каждая из задач имеет определенную «стоимость» (указана в скобках около задачи). Максимальная оценка за работу (без учёта бонусов) — 10 баллов.\n",
    "\n",
    "Сдавать задание после указанного жёсткого срока сдачи нельзя. При выставлении неполного балла за задание в связи с наличием ошибок на усмотрение проверяющего предусмотрена возможность исправить работу на указанных в ответном письме условиях.\n",
    "\n",
    "Задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов (подробнее о плагиате см. на странице курса). Если вы нашли решение какого-то из заданий (или его часть) в открытом источнике, необходимо указать ссылку на этот источник в отдельном блоке в конце вашей работы (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник).\n",
    "\n",
    "Неэффективная реализация кода может негативно отразиться на оценке.\n",
    "\n",
    "### Формат сдачи\n",
    "Задания сдаются через систему anytask. Посылка должна содержать:\n",
    "* Ноутбук homework-practice-08-random-features-Username.ipynb\n",
    "\n",
    "Username — ваша фамилия и имя на латинице именно в таком порядке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vY8vT0W_K-hR"
   },
   "source": [
    "### О задании\n",
    "\n",
    "На занятиях мы подробно обсуждали метод опорных векторов (SVM). В базовой версии в нём нет чего-то особенного — мы всего лишь используем специальную функцию потерь, которая не требует устремлять отступы к бесконечности; ей достаточно, чтобы отступы были не меньше +1. Затем мы узнали, что SVM можно переписать в двойственном виде, который, позволяет заменить скалярные произведения объектов на ядра. Это будет соответствовать построению модели в новом пространстве более высокой размерности, координаты которого представляют собой нелинейные модификации исходных признаков.\n",
    "\n",
    "Ядровой SVM, к сожалению, довольно затратен по памяти (нужно хранить матрицу Грама размера $d \\times d$) и по времени (нужно решать задачу условной оптимизации с квадратичной функцией, а это не очень быстро). Мы обсуждали, что есть способы посчитать новые признаки $\\tilde \\varphi(x)$ на основе исходных так, что скалярные произведения этих новых $\\langle \\tilde \\varphi(x), \\tilde \\varphi(z) \\rangle$ приближают ядро $K(x, z)$.\n",
    "\n",
    "Мы будем исследовать аппроксимации методом Random Fourier Features (RFF, также в литературе встречается название Random Kitchen Sinks) для гауссовых ядер. Будем использовать формулы, которые немного отличаются от того, что было на лекциях (мы добавим сдвиги внутрь тригонометрических функций и будем использовать только косинусы, потому что с нужным сдвигом косинус превратится в синус):\n",
    "$$\\tilde \\varphi(x) = (\n",
    "\\cos (w_1^T x + b_1),\n",
    "\\dots,\n",
    "\\cos (w_n^T x + b_n)\n",
    "),$$\n",
    "где $w_j \\sim \\mathcal{N}(0, 1/\\sigma^2)$, $b_j \\sim U[-\\pi, \\pi]$.\n",
    "\n",
    "На новых признаках $\\tilde \\varphi(x)$ мы будем строить любую линейную модель.\n",
    "\n",
    "Можно считать, что это некоторая новая парадигма построения сложных моделей. Можно направленно искать сложные нелинейные закономерности в данных с помощью градиентного бустинга или нейронных сетей, а можно просто нагенерировать большое количество случайных нелинейных признаков и надеяться, что быстрая и простая модель (то есть линейная) сможет показать на них хорошее качество. В этом задании мы изучим, насколько работоспособна такая идея.\n",
    "\n",
    "### Алгоритм\n",
    "\n",
    "Вам потребуется реализовать следующий алгоритм:\n",
    "1. Понизить размерность выборки до new_dim с помощью метода главных компонент.\n",
    "2. Для полученной выборки оценить гиперпараметр $\\sigma^2$ с помощью эвристики (рекомендуем считать медиану не по всем парам объектов, а по случайному подмножеству из где-то миллиона пар объектов): $$\\sigma^2 = \\text{median}_{i, j = 1, \\dots, \\ell, i \\neq j} \\left\\{\\sum_{k = 1}^{d} (x_{ik} - x_{jk})^2 \\right\\}$$\n",
    "3. Сгенерировать n_features наборов весов $w_j$ и сдвигов $b_j$.\n",
    "4. Сформировать n_features новых признаков по формулам, приведённым выше.\n",
    "5. Обучить линейную модель (логистическую регрессию или SVM) на новых признаках.\n",
    "6. Повторить преобразования (PCA, формирование новых признаков) к тестовой выборке и применить модель."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N_sGunb7K-hS"
   },
   "source": [
    "Тестировать алгоритм мы будем на данных Fashion MNIST. Ниже код для их загрузки и подготовки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: / \n",
      "The environment is inconsistent, please check the package plan carefully\n",
      "The following packages are causing the inconsistency:\n",
      "\n",
      "  - defaults/noarch::holoviews==1.14.8=pyhd3eb1b0_0\n",
      "  - defaults/osx-64::anaconda-navigator==2.2.0=py39hecd8cb5_0\n",
      "  - defaults/noarch::s3transfer==0.5.0=pyhd3eb1b0_0\n",
      "  - defaults/noarch::requests-file==1.5.1=pyhd3eb1b0_0\n",
      "  - defaults/noarch::smart_open==5.1.0=pyhd3eb1b0_0\n",
      "  - defaults/noarch::boto3==1.21.32=pyhd3eb1b0_0\n",
      "  - defaults/noarch::cookiecutter==1.7.3=pyhd3eb1b0_0\n",
      "  - defaults/noarch::google-cloud-core==1.7.1=pyhd3eb1b0_0\n",
      "  - defaults/osx-64::anaconda==2022.05=py39_0\n",
      "  - defaults/osx-64::conda==4.13.0=py39hecd8cb5_0\n",
      "  - defaults/noarch::datashader==0.13.0=pyhd3eb1b0_1\n",
      "  - defaults/noarch::conda-repo-cli==1.0.4=pyhd3eb1b0_0\n",
      "  - defaults/osx-64::conda-build==3.21.8=py39hecd8cb5_2\n",
      "  - defaults/noarch::sphinx==4.4.0=pyhd3eb1b0_0\n",
      "  - defaults/noarch::numpydoc==1.2=pyhd3eb1b0_0\n",
      "  - defaults/osx-64::scrapy==2.6.1=py39hecd8cb5_0\n",
      "  - defaults/osx-64::pyct==0.4.6=py39hecd8cb5_0\n",
      "  - defaults/noarch::google-auth==1.33.0=pyhd3eb1b0_0\n",
      "  - defaults/noarch::anaconda-project==0.10.2=pyhd3eb1b0_0\n",
      "  - defaults/osx-64::_ipyw_jlab_nb_ext_conf==0.1.0=py39hecd8cb5_1\n",
      "  - defaults/noarch::jupyterlab_server==2.10.3=pyhd3eb1b0_1\n",
      "  - defaults/noarch::botocore==1.24.32=pyhd3eb1b0_0\n",
      "  - defaults/osx-64::gensim==4.1.2=py39he9d5cce_0\n",
      "  - defaults/osx-64::anaconda-client==1.9.0=py39hecd8cb5_0\n",
      "  - defaults/noarch::requests==2.27.1=pyhd3eb1b0_0\n",
      "  - defaults/noarch::intake==0.6.5=pyhd3eb1b0_0\n",
      "  - defaults/noarch::google-api-core==1.25.1=pyhd3eb1b0_0\n",
      "  - defaults/noarch::google-cloud-storage==1.31.0=py_0\n",
      "  - defaults/osx-64::spyder==5.1.5=py39hecd8cb5_1\n",
      "  - defaults/noarch::hvplot==0.7.3=pyhd3eb1b0_1\n",
      "  - defaults/noarch::colorcet==2.0.6=pyhd3eb1b0_0\n",
      "  - defaults/noarch::conda-token==0.3.0=pyhd3eb1b0_0\n",
      "  - defaults/noarch::jupyterlab==3.3.2=pyhd3eb1b0_0\n",
      "  - defaults/noarch::tldextract==3.2.0=pyhd3eb1b0_0\n",
      "  - defaults/osx-64::panel==0.13.0=py39hecd8cb5_0\n",
      "failed with initial frozen solve. Retrying with flexible solve.\n",
      "Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: | \n",
      "The environment is inconsistent, please check the package plan carefully\n",
      "The following packages are causing the inconsistency:\n",
      "\n",
      "  - defaults/noarch::holoviews==1.14.8=pyhd3eb1b0_0\n",
      "  - defaults/osx-64::anaconda-navigator==2.2.0=py39hecd8cb5_0\n",
      "  - defaults/noarch::s3transfer==0.5.0=pyhd3eb1b0_0\n",
      "  - defaults/noarch::requests-file==1.5.1=pyhd3eb1b0_0\n",
      "  - defaults/noarch::smart_open==5.1.0=pyhd3eb1b0_0\n",
      "  - defaults/noarch::boto3==1.21.32=pyhd3eb1b0_0\n",
      "  - defaults/noarch::cookiecutter==1.7.3=pyhd3eb1b0_0\n",
      "  - defaults/noarch::google-cloud-core==1.7.1=pyhd3eb1b0_0\n",
      "  - defaults/osx-64::anaconda==2022.05=py39_0\n",
      "  - defaults/osx-64::conda==4.13.0=py39hecd8cb5_0\n",
      "  - defaults/noarch::datashader==0.13.0=pyhd3eb1b0_1\n",
      "  - defaults/noarch::conda-repo-cli==1.0.4=pyhd3eb1b0_0\n",
      "  - defaults/osx-64::conda-build==3.21.8=py39hecd8cb5_2\n",
      "  - defaults/noarch::sphinx==4.4.0=pyhd3eb1b0_0\n",
      "  - defaults/noarch::numpydoc==1.2=pyhd3eb1b0_0\n",
      "  - defaults/osx-64::scrapy==2.6.1=py39hecd8cb5_0\n",
      "  - defaults/osx-64::pyct==0.4.6=py39hecd8cb5_0\n",
      "  - defaults/noarch::google-auth==1.33.0=pyhd3eb1b0_0\n",
      "  - defaults/noarch::anaconda-project==0.10.2=pyhd3eb1b0_0\n",
      "  - defaults/osx-64::_ipyw_jlab_nb_ext_conf==0.1.0=py39hecd8cb5_1\n",
      "  - defaults/noarch::jupyterlab_server==2.10.3=pyhd3eb1b0_1\n",
      "  - defaults/noarch::botocore==1.24.32=pyhd3eb1b0_0\n",
      "  - defaults/osx-64::gensim==4.1.2=py39he9d5cce_0\n",
      "  - defaults/osx-64::anaconda-client==1.9.0=py39hecd8cb5_0\n",
      "  - defaults/noarch::requests==2.27.1=pyhd3eb1b0_0\n",
      "  - defaults/noarch::intake==0.6.5=pyhd3eb1b0_0\n",
      "  - defaults/noarch::google-api-core==1.25.1=pyhd3eb1b0_0\n",
      "  - defaults/noarch::google-cloud-storage==1.31.0=py_0\n",
      "  - defaults/osx-64::spyder==5.1.5=py39hecd8cb5_1\n",
      "  - defaults/noarch::hvplot==0.7.3=pyhd3eb1b0_1\n",
      "  - defaults/noarch::colorcet==2.0.6=pyhd3eb1b0_0\n",
      "  - defaults/noarch::conda-token==0.3.0=pyhd3eb1b0_0\n",
      "  - defaults/noarch::jupyterlab==3.3.2=pyhd3eb1b0_0\n",
      "  - defaults/noarch::tldextract==3.2.0=pyhd3eb1b0_0\n",
      "  - defaults/osx-64::panel==0.13.0=py39hecd8cb5_0\n",
      "done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.13.0\n",
      "  latest version: 23.1.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /Users/Arina/opt/anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - tensorflow\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    _anaconda_depends-2022.10  |           py39_2          69 KB\n",
      "    _tflow_select-2.2.0        |            eigen           3 KB\n",
      "    abseil-cpp-20211102.0      |       he9d5cce_0         933 KB\n",
      "    absl-py-1.3.0              |   py39hecd8cb5_0         168 KB\n",
      "    anaconda-custom            |           py39_1           4 KB\n",
      "    astunparse-1.6.3           |             py_0          17 KB\n",
      "    blinker-1.4                |   py39hecd8cb5_0          23 KB\n",
      "    ca-certificates-2023.01.10 |       hecd8cb5_0         121 KB\n",
      "    cctools-949.0.1            |      h9abeeb2_25          18 KB\n",
      "    cctools_osx-64-949.0.1     |      hc7db93f_25         1.3 MB\n",
      "    certifi-2022.12.7          |   py39hecd8cb5_0         151 KB\n",
      "    conda-build-3.23.3         |   py39hecd8cb5_0         568 KB\n",
      "    curl-7.84.0                |       hca72f7f_0          73 KB\n",
      "    flatbuffers-2.0.0          |       h23ab428_0         925 KB\n",
      "    gast-0.4.0                 |     pyhd3eb1b0_0          13 KB\n",
      "    google-auth-oauthlib-0.4.4 |     pyhd3eb1b0_0          18 KB\n",
      "    google-pasta-0.2.0         |     pyhd3eb1b0_0          46 KB\n",
      "    grpc-cpp-1.46.1            |       h067a048_0         2.5 MB\n",
      "    keras-2.9.0                |   py39hecd8cb5_0         1.5 MB\n",
      "    keras-preprocessing-1.1.2  |     pyhd3eb1b0_0          35 KB\n",
      "    ld64-530                   |      h20443b4_25          16 KB\n",
      "    ld64_osx-64-530            |      h70f3046_25         920 KB\n",
      "    ldid-2.1.2                 |       h2d21305_2          54 KB\n",
      "    libcurl-7.84.0             |       h6dfd666_0         309 KB\n",
      "    libllvm14-14.0.6           |       he552d86_0        21.3 MB\n",
      "    libprotobuf-3.20.1         |       h8346a28_0         1.8 MB\n",
      "    llvm-openmp-14.0.6         |       h0dcd299_0         288 KB\n",
      "    oauthlib-3.2.1             |   py39hecd8cb5_0         194 KB\n",
      "    openssl-1.1.1t             |       hca72f7f_0         3.3 MB\n",
      "    opt_einsum-3.3.0           |     pyhd3eb1b0_1          57 KB\n",
      "    patch-2.7.6                |    h1de35cc_1001         128 KB\n",
      "    protobuf-3.20.1            |   py39he9d5cce_0         279 KB\n",
      "    python-flatbuffers-1.12    |     pyhd3eb1b0_0          24 KB\n",
      "    re2-2022.04.01             |       he9d5cce_0         179 KB\n",
      "    requests-oauthlib-1.3.0    |             py_0          23 KB\n",
      "    sqlite-3.39.3              |       h707629a_0         1.2 MB\n",
      "    tapi-1000.10.8             |       ha1b3eb9_0         4.2 MB\n",
      "    tensorboard-2.9.0          |   py39hecd8cb5_0         5.5 MB\n",
      "    tensorboard-data-server-0.6.1|   py39h7242b5c_0         2.8 MB\n",
      "    tensorboard-plugin-wit-1.6.0|             py_0         630 KB\n",
      "    tensorflow-2.9.1           |eigen_py39h7123b6a_1           4 KB\n",
      "    tensorflow-base-2.9.1      |eigen_py39h36d2db2_1        96.6 MB\n",
      "    tensorflow-estimator-2.9.0 |   py39hecd8cb5_0         491 KB\n",
      "    termcolor-2.1.0            |   py39hecd8cb5_0          12 KB\n",
      "    urllib3-1.26.14            |   py39hecd8cb5_0         194 KB\n",
      "    wheel-0.35.1               |     pyhd3eb1b0_0          38 KB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:       149.0 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  _anaconda_depends  pkgs/main/osx-64::_anaconda_depends-2022.10-py39_2\n",
      "  _tflow_select      pkgs/main/osx-64::_tflow_select-2.2.0-eigen\n",
      "  abseil-cpp         pkgs/main/osx-64::abseil-cpp-20211102.0-he9d5cce_0\n",
      "  absl-py            pkgs/main/osx-64::absl-py-1.3.0-py39hecd8cb5_0\n",
      "  astunparse         pkgs/main/noarch::astunparse-1.6.3-py_0\n",
      "  blinker            pkgs/main/osx-64::blinker-1.4-py39hecd8cb5_0\n",
      "  cctools            pkgs/main/osx-64::cctools-949.0.1-h9abeeb2_25\n",
      "  cctools_osx-64     pkgs/main/osx-64::cctools_osx-64-949.0.1-hc7db93f_25\n",
      "  flatbuffers        pkgs/main/osx-64::flatbuffers-2.0.0-h23ab428_0\n",
      "  gast               pkgs/main/noarch::gast-0.4.0-pyhd3eb1b0_0\n",
      "  google-auth-oauth~ pkgs/main/noarch::google-auth-oauthlib-0.4.4-pyhd3eb1b0_0\n",
      "  google-pasta       pkgs/main/noarch::google-pasta-0.2.0-pyhd3eb1b0_0\n",
      "  grpc-cpp           pkgs/main/osx-64::grpc-cpp-1.46.1-h067a048_0\n",
      "  keras              pkgs/main/osx-64::keras-2.9.0-py39hecd8cb5_0\n",
      "  keras-preprocessi~ pkgs/main/noarch::keras-preprocessing-1.1.2-pyhd3eb1b0_0\n",
      "  ld64               pkgs/main/osx-64::ld64-530-h20443b4_25\n",
      "  ld64_osx-64        pkgs/main/osx-64::ld64_osx-64-530-h70f3046_25\n",
      "  ldid               pkgs/main/osx-64::ldid-2.1.2-h2d21305_2\n",
      "  libllvm14          pkgs/main/osx-64::libllvm14-14.0.6-he552d86_0\n",
      "  oauthlib           pkgs/main/osx-64::oauthlib-3.2.1-py39hecd8cb5_0\n",
      "  opt_einsum         pkgs/main/noarch::opt_einsum-3.3.0-pyhd3eb1b0_1\n",
      "  patch              pkgs/main/osx-64::patch-2.7.6-h1de35cc_1001\n",
      "  python-flatbuffers pkgs/main/noarch::python-flatbuffers-1.12-pyhd3eb1b0_0\n",
      "  re2                pkgs/main/osx-64::re2-2022.04.01-he9d5cce_0\n",
      "  requests-oauthlib  pkgs/main/noarch::requests-oauthlib-1.3.0-py_0\n",
      "  tapi               pkgs/main/osx-64::tapi-1000.10.8-ha1b3eb9_0\n",
      "  tensorboard        pkgs/main/osx-64::tensorboard-2.9.0-py39hecd8cb5_0\n",
      "  tensorboard-data-~ pkgs/main/osx-64::tensorboard-data-server-0.6.1-py39h7242b5c_0\n",
      "  tensorboard-plugi~ pkgs/main/noarch::tensorboard-plugin-wit-1.6.0-py_0\n",
      "  tensorflow         pkgs/main/osx-64::tensorflow-2.9.1-eigen_py39h7123b6a_1\n",
      "  tensorflow-base    pkgs/main/osx-64::tensorflow-base-2.9.1-eigen_py39h36d2db2_1\n",
      "  tensorflow-estima~ pkgs/main/osx-64::tensorflow-estimator-2.9.0-py39hecd8cb5_0\n",
      "  termcolor          pkgs/main/osx-64::termcolor-2.1.0-py39hecd8cb5_0\n",
      "  urllib3            pkgs/main/osx-64::urllib3-1.26.14-py39hecd8cb5_0\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates                      2022.3.29-hecd8cb5_1 --> 2023.01.10-hecd8cb5_0\n",
      "  certifi                          2021.10.8-py39hecd8cb5_2 --> 2022.12.7-py39hecd8cb5_0\n",
      "  conda-build                         3.21.8-py39hecd8cb5_2 --> 3.23.3-py39hecd8cb5_0\n",
      "  curl                                    7.82.0-hca72f7f_0 --> 7.84.0-hca72f7f_0\n",
      "  libcurl                                 7.82.0-h6dfd666_0 --> 7.84.0-h6dfd666_0\n",
      "  libprotobuf                             3.19.1-h8346a28_0 --> 3.20.1-h8346a28_0\n",
      "  llvm-openmp                             12.0.0-h0dcd299_1 --> 14.0.6-h0dcd299_0\n",
      "  openssl                                 1.1.1n-hca72f7f_0 --> 1.1.1t-hca72f7f_0\n",
      "  protobuf                            3.19.1-py39he9d5cce_0 --> 3.20.1-py39he9d5cce_0\n",
      "  sqlite                                  3.38.2-h707629a_0 --> 3.39.3-h707629a_0\n",
      "\n",
      "The following packages will be DOWNGRADED:\n",
      "\n",
      "  anaconda                                   2022.05-py39_0 --> custom-py39_1\n",
      "  wheel                                 0.37.1-pyhd3eb1b0_0 --> 0.35.1-pyhd3eb1b0_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cctools_osx-64-949.0 | 1.3 MB    | ##################################### | 100% \n",
      "tensorflow-estimator | 491 KB    | ##################################### | 100% \n",
      "astunparse-1.6.3     | 17 KB     | ##################################### | 100% \n",
      "opt_einsum-3.3.0     | 57 KB     | ##################################### | 100% \n",
      "urllib3-1.26.14      | 194 KB    | ##################################### | 100% \n",
      "keras-preprocessing- | 35 KB     | ##################################### | 100% \n",
      "tensorboard-data-ser | 2.8 MB    | ##################################### | 100% \n",
      "re2-2022.04.01       | 179 KB    | ##################################### | 100% \n",
      "tensorboard-2.9.0    | 5.5 MB    | ##################################### | 100% \n",
      "ca-certificates-2023 | 121 KB    | ##################################### | 100% \n",
      "anaconda-custom      | 4 KB      | ##################################### | 100% \n",
      "grpc-cpp-1.46.1      | 2.5 MB    | ##################################### | 100% \n",
      "requests-oauthlib-1. | 23 KB     | ##################################### | 100% \n",
      "flatbuffers-2.0.0    | 925 KB    | ##################################### | 100% \n",
      "ld64-530             | 16 KB     | ##################################### | 100% \n",
      "ld64_osx-64-530      | 920 KB    | ##################################### | 100% \n",
      "patch-2.7.6          | 128 KB    | ##################################### | 100% \n",
      "_tflow_select-2.2.0  | 3 KB      | ##################################### | 100% \n",
      "tapi-1000.10.8       | 4.2 MB    | ##################################### | 100% \n",
      "libprotobuf-3.20.1   | 1.8 MB    | ##################################### | 100% \n",
      "openssl-1.1.1t       | 3.3 MB    | ##################################### | 100% \n",
      "ldid-2.1.2           | 54 KB     | ##################################### | 100% \n",
      "oauthlib-3.2.1       | 194 KB    | ##################################### | 100% \n",
      "libllvm14-14.0.6     | 21.3 MB   | ##################################### | 100% \n",
      "sqlite-3.39.3        | 1.2 MB    | ##################################### | 100% \n",
      "abseil-cpp-20211102. | 933 KB    | ##################################### | 100% \n",
      "absl-py-1.3.0        | 168 KB    | ##################################### | 100% \n",
      "python-flatbuffers-1 | 24 KB     | ##################################### | 100% \n",
      "llvm-openmp-14.0.6   | 288 KB    | ##################################### | 100% \n",
      "cctools-949.0.1      | 18 KB     | ##################################### | 100% \n",
      "keras-2.9.0          | 1.5 MB    | ##################################### | 100% \n",
      "_anaconda_depends-20 | 69 KB     | ##################################### | 100% \n",
      "protobuf-3.20.1      | 279 KB    | ##################################### | 100% \n",
      "certifi-2022.12.7    | 151 KB    | ##################################### | 100% \n",
      "google-pasta-0.2.0   | 46 KB     | ##################################### | 100% \n",
      "libcurl-7.84.0       | 309 KB    | ##################################### | 100% \n",
      "termcolor-2.1.0      | 12 KB     | ##################################### | 100% \n",
      "tensorflow-base-2.9. | 96.6 MB   | ##################################### | 100% \n",
      "conda-build-3.23.3   | 568 KB    | ##################################### | 100% \n",
      "curl-7.84.0          | 73 KB     | ##################################### | 100% \n",
      "gast-0.4.0           | 13 KB     | ##################################### | 100% \n",
      "blinker-1.4          | 23 KB     | ##################################### | 100% \n",
      "tensorboard-plugin-w | 630 KB    | ##################################### | 100% \n",
      "google-auth-oauthlib | 18 KB     | ##################################### | 100% \n",
      "wheel-0.35.1         | 38 KB     | ##################################### | 100% \n",
      "tensorflow-2.9.1     | 4 KB      | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#conda install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "YyG6dBfjK-hS"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import fashion_mnist\n",
    "(x_train_pics, y_train), (x_test_pics, y_test) = fashion_mnist.load_data()\n",
    "x_train = x_train_pics.reshape(y_train.shape[0], -1)\n",
    "x_test = x_test_pics.reshape(y_test.shape[0], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rJNN55F7K-hT"
   },
   "source": [
    "__Задание 1. (5 баллов)__\n",
    "\n",
    "Реализуйте алгоритм, описанный выше. Можете воспользоваться шаблоном класса ниже или написать свой интерфейс.\n",
    "\n",
    "Ваша реализация должна поддерживать следующие опции:\n",
    "1. Возможность задавать значения гиперпараметров new_dim (по умолчанию 50) и n_features (по умолчанию 1000).\n",
    "2. Возможность включать или выключать предварительное понижение размерности с помощью метода главных компонент.\n",
    "3. Возможность выбирать тип линейной модели (логистическая регрессия или SVM с линейным ядром).\n",
    "\n",
    "Протестируйте на данных Fashion MNIST, сформированных кодом выше. Если на тесте у вас получилась доля верных ответов не ниже 0.84 с гиперпараметрами по умолчанию, то вы всё сделали правильно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "JIhRbvV3nkAI"
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "class RFFPipeline(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_features=1000, new_dim=50, use_PCA=True, classifier='logreg'):\n",
    "        \"\"\"        \n",
    "        Implements pipeline, which consists of PCA decomposition,\n",
    "        Random Fourier Features approximation and linear classification model.\n",
    "        \n",
    "        n_features, int: amount of synthetic random features generated with RFF approximation.\n",
    "\n",
    "        new_dim, int: PCA output size.\n",
    "        \n",
    "        use_PCA, bool: whether to include PCA preprocessing.\n",
    "        \n",
    "        classifier, string: either 'svm' or 'logreg', a linear classification model to use on top of pipeline.\n",
    "        \n",
    "        Feel free to edit this template for your preferences.    \n",
    "        \"\"\"\n",
    "        self.n_features = n_features\n",
    "        self.use_PCA = use_PCA\n",
    "        self.new_dim = new_dim\n",
    "        self.classifier = classifier\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit all parts of algorithm (PCA, RFF, Classification) to training set.\n",
    "        \"\"\"\n",
    "        # Your code here: (￣▽￣)/♫•*¨*•.¸¸♪\n",
    "\n",
    "        #PCA\n",
    "        if self.use_PCA == True:\n",
    "            self.pca = PCA(n_components=self.new_dim)\n",
    "            X = self.pca.fit_transform(X)\n",
    "  \n",
    "        \n",
    "\n",
    "        #RFF\n",
    "        #let's find sigma\n",
    "        id1 = np.random.randint(X.shape[0], size=1000000)\n",
    "        id2 = np.random.randint(X.shape[0], size=1000000)\n",
    "        sigma = np.sqrt(np.median(np.sum((X[id1] - X[id2])**2, axis = 1)))\n",
    "\n",
    "        #let's generate w and b\n",
    "        np.random.seed(0)\n",
    "        self.w = np.random.normal(0, 1/sigma, size = (X.shape[1], self.n_features))\n",
    "        self.b = np.random.uniform(-math.pi, math.pi, size = (self.n_features))\n",
    "\n",
    "        #let's generate new features\n",
    "        X_new = np.cos(X.dot(self.w) + self.b)\n",
    "\n",
    "\n",
    "        \n",
    "        #MODEL\n",
    "        if self.classifier == 'logreg':\n",
    "            self.model = LogisticRegression(random_state=0).fit(X_new, y)\n",
    "\n",
    "        elif self.classifier == 'svm':\n",
    "            self.model = LinearSVC(random_state=0).fit(X_new, y)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Apply pipeline to obtain scores for input data.\n",
    "        \"\"\"\n",
    "        # Your code here: (￣▽￣)/♫•*¨*•.¸¸♪\n",
    "\n",
    "        #PCA\n",
    "        if self.use_PCA == True:\n",
    "            X = self.pca.transform(X)\n",
    "  \n",
    "        \n",
    "\n",
    "        #RFF\n",
    "        #let's generate new features\n",
    "        X_new = np.cos(X.dot(self.w) + self.b)\n",
    "\n",
    "\n",
    "\n",
    "        #PREDICTIONS\n",
    "        predictions_prob = self.model.predict_proba(X_new)\n",
    "\n",
    "        return predictions_prob\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Apply pipeline to obtain discrete predictions for input data.\n",
    "        \"\"\"\n",
    "        # Your code here: (￣▽￣)/♫•*¨*•.¸¸♪\n",
    "\n",
    "        #PCA\n",
    "        if self.use_PCA == True:\n",
    "            X = self.pca.transform(X)\n",
    "  \n",
    "        \n",
    "\n",
    "        #RFF\n",
    "        #let's generate new features\n",
    "        X_new = np.cos(X.dot(self.w) + self.b)\n",
    "\n",
    "\n",
    "\n",
    "        #PREDICTIONS\n",
    "        predictions = self.model.predict(X_new)\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0IT5_XaxbArW",
    "outputId": "9881cc17-cfa7-4667-978d-4fadba905c2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA + RFF + Logreg: accuracy = 0.8584, time = 20.155084133148193\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import time \n",
    "\n",
    "#PCA + RFF + Logreg\n",
    "start = time.time()\n",
    "rff = RFFPipeline() \n",
    "rff = rff.fit(x_train, y_train)\n",
    "y_pred = rff.predict(x_test)\n",
    "acc1 = accuracy_score(y_test, y_pred)\n",
    "end = time.time() - start \n",
    "print(f'PCA + RFF + Logreg: accuracy = {acc1}, time = {end}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HYqQUEi-K-hU"
   },
   "source": [
    "__Задание 2. (3 балла)__\n",
    "\n",
    "Сравните подход со случайными признаками с обучением SVM на исходных признаках. Попробуйте вариант с обычным (линейным) SVM и с ядровым SVM. Ядровой SVM может очень долго обучаться, поэтому можно делать любые разумные вещи для ускорения: брать подмножество объектов из обучающей выборки, например.\n",
    "\n",
    "Сравните подход со случайными признаками с вариантом, в котором вы понижаете размерность с помощью PCA и обучаете градиентный бустинг. Используйте одну из реализаций CatBoost/LightGBM/XGBoost, не забудьте подобрать число деревьев и длину шага.\n",
    "\n",
    "Сделайте выводы — насколько идея со случайными признаками работает? Сравните как с точки зрения качества, так и с точки зрения скорости обучения и применения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qN8LUlJgK-hV",
    "outputId": "d2f51a44-5193-4adc-e70f-12fd358ba6c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel SVM on initial data: accuracy = 0.8828, training time = 297.6544988155365, testing time = 70.27885007858276\n"
     ]
    }
   ],
   "source": [
    "#kernel SVM on initial data\n",
    "start_train = time.time()\n",
    "SVM_k_initial = SVC(kernel='rbf', random_state=0).fit(x_train, y_train)\n",
    "end_train = time.time() - start_train\n",
    "start_test = time.time()\n",
    "y_pred_SVM_k_initial = SVM_k_initial.predict(x_test)\n",
    "end_test = time.time() - start_test \n",
    "acc2 = accuracy_score(y_test, y_pred_SVM_k_initial)\n",
    "print(f'Kernel SVM on initial data: accuracy = {acc2}, training time = {end_train}, testing time = {end_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tyoTOAf-MQhE",
    "outputId": "1313fb43-968c-43fb-d424-98d4386c7966"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM on initial data: accuracy = 0.8828, training time = 298.08090686798096, testing time = 70.39896392822266\n"
     ]
    }
   ],
   "source": [
    "#linear SVM on initial data\n",
    "start_train = time.time()\n",
    "SVM_initial = SVC(random_state=0).fit(x_train, y_train)\n",
    "end_train = time.time() - start_train\n",
    "start_test = time.time()\n",
    "y_pred_SVM_initial = SVM_initial.predict(x_test)\n",
    "end_test = time.time() - start_test\n",
    "acc3 = accuracy_score(y_test, y_pred_SVM_initial)\n",
    "print(f'Linear SVM on initial data: accuracy = {acc3}, training time = {end_train}, testing time = {end_test}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fso3vORvzmK0",
    "outputId": "8bb55c3f-f712-44d6-bc05-713262a6a708"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA + RFF + linear SVM: accuracy = 0.8688, training time = 260.63614106178284, testing time = 0.2239077091217041\n"
     ]
    }
   ],
   "source": [
    "#PCA + RFF + linear SVM\n",
    "start_train = time.time()\n",
    "rff_PCA_SVM = RFFPipeline(n_features=1000, new_dim=50, use_PCA=True, classifier='svm') \n",
    "rff_PCA_SVM  = rff_PCA_SVM.fit(x_train, y_train)\n",
    "end_train = time.time() - start_train\n",
    "start_test = time.time()\n",
    "y_pred_rff_PCA_SVM  = rff_PCA_SVM.predict(x_test)\n",
    "end_test = time.time() - start_test\n",
    "acc7 = accuracy_score(y_test, y_pred_rff_PCA_SVM)\n",
    "print(f'PCA + RFF + linear SVM: accuracy = {acc7}, training time = {end_train}, testing time = {end_test}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b950UB8Qnwhd",
    "outputId": "ad5a4170-7cab-4a12-d0b4-a99cf3f66936"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost with PCA: accuracy = 0.874, training time = 229.69751906394958, testing time = 0.1518232822418213\n"
     ]
    }
   ],
   "source": [
    "#CatBoost with PCA\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "start_train = time.time()\n",
    "pca = PCA(n_components=50)\n",
    "x_train_pca = pca.fit_transform(x_train)\n",
    "\n",
    "cat = CatBoostClassifier(learning_rate = 0.03, depth = 10, verbose = False)\n",
    "cat = cat.fit(x_train_pca, y_train)\n",
    "end_train = time.time() - start_train\n",
    "start_test = time.time()\n",
    "x_test_pca = pca.transform(x_test)\n",
    "y_pred_cat = cat.predict(x_test_pca)\n",
    "end_test = time.time() - start_test\n",
    "acc4 = accuracy_score(y_test, y_pred_cat)\n",
    "print(f'CatBoost with PCA: accuracy = {acc4}, training time = {end_train}, testing time = {end_test}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0IT5_XaxbArW",
    "outputId": "9881cc17-cfa7-4667-978d-4fadba905c2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA + RFF + Logreg: accuracy = 0.8571, training time = 19.048567056655884, testing time = 0.23002195358276367\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import time \n",
    "\n",
    "#PCA + RFF + Logreg\n",
    "start_train = time.time()\n",
    "rff = RFFPipeline() \n",
    "rff = rff.fit(x_train, y_train)\n",
    "end_train = time.time() - start_train\n",
    "start_test = time.time()\n",
    "y_pred = rff.predict(x_test)\n",
    "end_test = time.time() - start_test\n",
    "acc1 = accuracy_score(y_test, y_pred)\n",
    "print(f'PCA + RFF + Logreg: accuracy = {acc1}, training time = {end_train}, testing time = {end_test}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Выводы:** как видим, каждый из представленных подходов дает примерно одинаковое высокое качество. \n",
    "\n",
    "При сравнении SVM на исходных данных с PCA + RFF + linear SVM можно сделать вывод, что третий вариант дает лучшие результаты с точки зрения времени: время и обучения, и применения ниже, чем у обоих вариантов SVM на исходных данных. \n",
    "\n",
    "Однако выигрышнее всех трех описанных выше вариантов оказался бустинг с PCA: результаты выше и с точки зрения качества, и с точки зрения времени. Но в сравнении бустинга с PCA + RFF + Logreg логрег со случайными признаками дает качество несильно ниже кэтбуста, но при этом время обучения значительно ниже у логистической регрессии. \n",
    "\n",
    "Таким образом, подход со случайными признаками кажется оптимальным вариантом, поскольку он дает такие же высокие метрики качества, но по времени оказывается быстрее. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e6umjhWuK-hV"
   },
   "source": [
    "__Задание 3. (2 балла)__\n",
    "\n",
    "Проведите эксперименты:\n",
    "1. Помогает ли предварительное понижение размерности с помощью PCA? \n",
    "2. Как зависит итоговое качество от n_features? Выходит ли оно на плато при росте n_features?\n",
    "3. Важно ли, какую модель обучать — логистическую регрессию или SVM?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Исследуем влияние понижения размерности через PCA на результаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "DSZexA2Mn5h4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFF + linear SVM: accuracy = 0.8566, training time = 281.3163697719574, testing time = 0.39263415336608887\n"
     ]
    }
   ],
   "source": [
    "#RFF + linear SVM\n",
    "start_train = time.time()\n",
    "rff_SVM = RFFPipeline(n_features=1000, new_dim=50, use_PCA=False, classifier='svm') \n",
    "rff_SVM = rff_SVM.fit(x_train.astype(np.float64), y_train)\n",
    "end_train = time.time() - start_train\n",
    "start_test = time.time()\n",
    "y_pred_rff_SVM = rff_SVM.predict(x_test)\n",
    "end_test = time.time() - start_test\n",
    "acc6 = accuracy_score(y_test, y_pred_rff_SVM)\n",
    "print(f'RFF + linear SVM: accuracy = {acc6}, training time = {end_train}, testing time = {end_test}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fso3vORvzmK0",
    "outputId": "8bb55c3f-f712-44d6-bc05-713262a6a708"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA + RFF + linear SVM: accuracy = 0.8688, training time = 260.63614106178284, testing time = 0.2239077091217041\n"
     ]
    }
   ],
   "source": [
    "#PCA + RFF + linear SVM\n",
    "start_train = time.time()\n",
    "rff_PCA_SVM = RFFPipeline(n_features=1000, new_dim=50, use_PCA=True, classifier='svm') \n",
    "rff_PCA_SVM  = rff_PCA_SVM.fit(x_train, y_train)\n",
    "end_train = time.time() - start_train\n",
    "start_test = time.time()\n",
    "y_pred_rff_PCA_SVM  = rff_PCA_SVM.predict(x_test)\n",
    "end_test = time.time() - start_test\n",
    "acc7 = accuracy_score(y_test, y_pred_rff_PCA_SVM)\n",
    "print(f'PCA + RFF + linear SVM: accuracy = {acc7}, training time = {end_train}, testing time = {end_test}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "c2QIHIMbK-hW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFF + Logreg: accuracy = 0.8666, training time = 34.315184116363525, testing time = 0.4032912254333496\n"
     ]
    }
   ],
   "source": [
    "#RFF + Logreg\n",
    "start_train = time.time()\n",
    "rff_logreg = RFFPipeline(n_features=1000, new_dim=50, use_PCA=False, classifier='logreg') \n",
    "rff_logreg = rff_logreg.fit(x_train.astype(np.float64), y_train)\n",
    "end_train = time.time() - start_train\n",
    "start_test = time.time()\n",
    "y_pred_rff_logreg = rff_logreg.predict(x_test)\n",
    "end_test = time.time() - start_test\n",
    "acc5 = accuracy_score(y_test, y_pred_rff_logreg)\n",
    "print(f'RFF + Logreg: accuracy = {acc5}, training time = {end_train}, testing time = {end_test}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0IT5_XaxbArW",
    "outputId": "9881cc17-cfa7-4667-978d-4fadba905c2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA + RFF + Logreg: accuracy = 0.8571, training time = 19.048567056655884, testing time = 0.23002195358276367\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import time \n",
    "\n",
    "#PCA + RFF + Logreg\n",
    "start_train = time.time()\n",
    "rff = RFFPipeline() \n",
    "rff = rff.fit(x_train, y_train)\n",
    "end_train = time.time() - start_train\n",
    "start_test = time.time()\n",
    "y_pred = rff.predict(x_test)\n",
    "end_test = time.time() - start_test\n",
    "acc1 = accuracy_score(y_test, y_pred)\n",
    "print(f'PCA + RFF + Logreg: accuracy = {acc1}, training time = {end_train}, testing time = {end_test}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значит, предварительное поонижение размерности с PCA позволяет снизить время обучения и применения модели, а также в некоторых случаях увеличить качество модели.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Проверим зависимость качества от n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies_l = []\n",
    "accuracies_s = []\n",
    "for i in [100, 250, 500, 1000, 2000, 3000]:\n",
    "    #PCA + RFF + Logreg\n",
    "    rff_logreg = RFFPipeline(n_features=i, new_dim=50, use_PCA=True, classifier='logreg') \n",
    "    rff_logreg = rff_logreg.fit(x_train.astype(np.float64), y_train)\n",
    "    y_pred_logreg = rff_logreg.predict(x_test)\n",
    "    acc_l = accuracy_score(y_test, y_pred_logreg)\n",
    "    accuracies_l.append(acc_l)\n",
    "    \n",
    "    #PCA + RFF + linear SVM\n",
    "    rff_svm = RFFPipeline(n_features=i, new_dim=50, use_PCA=True, classifier='svm') \n",
    "    rff_svm = rff_svm.fit(x_train.astype(np.float64), y_train)\n",
    "    y_pred_svm = rff_svm.predict(x_test)\n",
    "    acc_s = accuracy_score(y_test, y_pred_svm)\n",
    "    accuracies_s.append(acc_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x = [100, 250, 500, 1000, 2000, 3000]\n",
    "\n",
    "plt.plot(x, accuracies_l, label='PCA + RFF + Logreg')\n",
    "plt.plot(x, accuracies_s, label='PCA + RFF + linear SVM')\n",
    "plt.legend()\n",
    "plt.title('Accuracy with different n_features')\n",
    "plt.xlabel('n_features')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, в случае с логрегом качество, и вправду, выходит на плато, однако качество на SVM продолжает расти с увеличением n_features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Из всех проведенных выше экспериментов можно сделать вывод, что SVM дает более высокий результат с точки зрения качества, однако линейная регрессия гораздо быстрее обучается и применяется. Таким образом, выбор между моделями должен строиться относительно целей: в случае если требуется получить как можно более высокое качество, то следует использовать SVM, а если важна оперативность модели - линейную регрессию. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CJqXVuasK-hW"
   },
   "source": [
    "### Бонус"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QVDWHCdrK-hX"
   },
   "source": [
    "__Задание 4. (Максимум 2 балла)__\n",
    "\n",
    "Как вы, должно быть, помните с курса МО-1, многие алгоритмы машинного обучения работают лучше, если признаки данных некоррелированы. Оказывается, что для RFF существует модификация, позволяющая получать ортогональные случайные признаки (Orthogonal Random Features, ORF). Об этом методе можно прочитать в [статье](https://proceedings.neurips.cc/paper/2016/file/53adaf494dc89ef7196d73636eb2451b-Paper.pdf). Реализуйте класс для вычисления ORF по аналогии с основным заданием. Обратите внимание, что ваш класс должен уметь работать со случаем n_features > new_dim (в статье есть замечание на этот счет). Проведите эксперименты, сравнивающие RFF и ORF, сделайте выводы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HSxvGI9iK-hX"
   },
   "outputs": [],
   "source": [
    "# Your code here: (￣▽￣)/♫•*¨*•.¸¸♪"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4pc7-1jmK-hY"
   },
   "source": [
    "__Задание 5. (Максимум 2 балла)__\n",
    "\n",
    "Поэкспериментируйте с функциями для вычисления новых случайных признаков. Не обязательно использовать косинус от скалярного произведения — можно брать знак от него, хэш и т.д. Придумайте побольше вариантов для генерации признаков и проверьте, не получается ли с их помощью добиваться более высокого качества. Также можете попробовать другой классификатор поверх случайных признаков, сравните результаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dWj-O2vjK-hY"
   },
   "outputs": [],
   "source": [
    "# Your code here: (￣▽￣)/♫•*¨*•.¸¸♪"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Эксперименты с функцией в RFF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "JIhRbvV3nkAI"
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "class RFFPipeline(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_features=1000, new_dim=50, use_PCA=True, classifier='logreg'):\n",
    "        \"\"\"        \n",
    "        Implements pipeline, which consists of PCA decomposition,\n",
    "        Random Fourier Features approximation and linear classification model.\n",
    "        \n",
    "        n_features, int: amount of synthetic random features generated with RFF approximation.\n",
    "\n",
    "        new_dim, int: PCA output size.\n",
    "        \n",
    "        use_PCA, bool: whether to include PCA preprocessing.\n",
    "        \n",
    "        classifier, string: either 'svm' or 'logreg', a linear classification model to use on top of pipeline.\n",
    "        \n",
    "        Feel free to edit this template for your preferences.    \n",
    "        \"\"\"\n",
    "        self.n_features = n_features\n",
    "        self.use_PCA = use_PCA\n",
    "        self.new_dim = new_dim\n",
    "        self.classifier = classifier\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit all parts of algorithm (PCA, RFF, Classification) to training set.\n",
    "        \"\"\"\n",
    "        # Your code here: (￣▽￣)/♫•*¨*•.¸¸♪\n",
    "\n",
    "        #PCA\n",
    "        if self.use_PCA == True:\n",
    "            self.pca = PCA(n_components=self.new_dim)\n",
    "            X = self.pca.fit_transform(X)\n",
    "  \n",
    "        \n",
    "\n",
    "        #RFF\n",
    "        #let's find sigma\n",
    "        id1 = np.random.randint(X.shape[0], size=1000000)\n",
    "        id2 = np.random.randint(X.shape[0], size=1000000)\n",
    "        sigma = np.sqrt(np.median(np.sum((X[id1] - X[id2])**2, axis = 1)))\n",
    "\n",
    "        #let's generate w and b\n",
    "        np.random.seed(0)\n",
    "        self.w = np.random.normal(0, 1/sigma, size = (X.shape[1], self.n_features))\n",
    "        self.b = np.random.uniform(-math.pi, math.pi, size = (self.n_features))\n",
    "\n",
    "        #let's generate new features\n",
    "        X_new = np.cos(X.dot(self.w) + self.b)\n",
    "\n",
    "\n",
    "        \n",
    "        #MODEL\n",
    "        if self.classifier == 'logreg':\n",
    "            self.model = LogisticRegression(random_state=0).fit(X_new, y)\n",
    "\n",
    "        elif self.classifier == 'svm':\n",
    "            self.model = LinearSVC(random_state=0).fit(X_new, y)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Apply pipeline to obtain scores for input data.\n",
    "        \"\"\"\n",
    "        # Your code here: (￣▽￣)/♫•*¨*•.¸¸♪\n",
    "\n",
    "        #PCA\n",
    "        if self.use_PCA == True:\n",
    "            X = self.pca.transform(X)\n",
    "  \n",
    "        \n",
    "\n",
    "        #RFF\n",
    "        #let's generate new features\n",
    "        X_new = np.cos(X.dot(self.w) + self.b)\n",
    "\n",
    "\n",
    "\n",
    "        #PREDICTIONS\n",
    "        predictions_prob = self.model.predict_proba(X_new)\n",
    "\n",
    "        return predictions_prob\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Apply pipeline to obtain discrete predictions for input data.\n",
    "        \"\"\"\n",
    "        # Your code here: (￣▽￣)/♫•*¨*•.¸¸♪\n",
    "\n",
    "        #PCA\n",
    "        if self.use_PCA == True:\n",
    "            X = self.pca.transform(X)\n",
    "  \n",
    "        \n",
    "\n",
    "        #RFF\n",
    "        #let's generate new features\n",
    "        X_new = np.cos(X.dot(self.w) + self.b)\n",
    "\n",
    "\n",
    "\n",
    "        #PREDICTIONS\n",
    "        predictions = self.model.predict(X_new)\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0IT5_XaxbArW",
    "outputId": "9881cc17-cfa7-4667-978d-4fadba905c2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA + RFF(cos) + Logreg: accuracy = 0.8615, time = 26.794602155685425\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import time \n",
    "\n",
    "#PCA + RFF + Logreg\n",
    "start = time.time()\n",
    "rff = RFFPipeline() \n",
    "rff = rff.fit(x_train, y_train)\n",
    "y_pred = rff.predict(x_test)\n",
    "acc1 = accuracy_score(y_test, y_pred)\n",
    "end = time.time() - start \n",
    "print(f'PCA + RFF(cos) + Logreg: accuracy = {acc1}, time = {end}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "JIhRbvV3nkAI"
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.special import expit\n",
    "\n",
    "class RFFPipeline(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_features=1000, new_dim=50, use_PCA=True, classifier='logreg'):\n",
    "        \"\"\"        \n",
    "        Implements pipeline, which consists of PCA decomposition,\n",
    "        Random Fourier Features approximation and linear classification model.\n",
    "        \n",
    "        n_features, int: amount of synthetic random features generated with RFF approximation.\n",
    "\n",
    "        new_dim, int: PCA output size.\n",
    "        \n",
    "        use_PCA, bool: whether to include PCA preprocessing.\n",
    "        \n",
    "        classifier, string: either 'svm' or 'logreg', a linear classification model to use on top of pipeline.\n",
    "        \n",
    "        Feel free to edit this template for your preferences.    \n",
    "        \"\"\"\n",
    "        self.n_features = n_features\n",
    "        self.use_PCA = use_PCA\n",
    "        self.new_dim = new_dim\n",
    "        self.classifier = classifier\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit all parts of algorithm (PCA, RFF, Classification) to training set.\n",
    "        \"\"\"\n",
    "        # Your code here: (￣▽￣)/♫•*¨*•.¸¸♪\n",
    "\n",
    "        #PCA\n",
    "        if self.use_PCA == True:\n",
    "            self.pca = PCA(n_components=self.new_dim)\n",
    "            X = self.pca.fit_transform(X)\n",
    "  \n",
    "        \n",
    "\n",
    "        #RFF\n",
    "        #let's find sigma\n",
    "        id1 = np.random.randint(X.shape[0], size=1000000)\n",
    "        id2 = np.random.randint(X.shape[0], size=1000000)\n",
    "        sigma = np.sqrt(np.median(np.sum((X[id1] - X[id2])**2, axis = 1)))\n",
    "\n",
    "        #let's generate w and b\n",
    "        np.random.seed(0)\n",
    "        self.w = np.random.normal(0, 1/sigma, size = (X.shape[1], self.n_features))\n",
    "        self.b = np.random.uniform(-math.pi, math.pi, size = (self.n_features))\n",
    "\n",
    "        #let's generate new features\n",
    "        X_new = expit(X.dot(self.w) + self.b)\n",
    "\n",
    "\n",
    "        \n",
    "        #MODEL\n",
    "        if self.classifier == 'logreg':\n",
    "            self.model = LogisticRegression(random_state=0).fit(X_new, y)\n",
    "\n",
    "        elif self.classifier == 'svm':\n",
    "            self.model = LinearSVC(random_state=0).fit(X_new, y)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Apply pipeline to obtain scores for input data.\n",
    "        \"\"\"\n",
    "        # Your code here: (￣▽￣)/♫•*¨*•.¸¸♪\n",
    "\n",
    "        #PCA\n",
    "        if self.use_PCA == True:\n",
    "            X = self.pca.transform(X)\n",
    "  \n",
    "        \n",
    "\n",
    "        #RFF\n",
    "        #let's generate new features\n",
    "        X_new = expit(X.dot(self.w) + self.b)\n",
    "\n",
    "\n",
    "\n",
    "        #PREDICTIONS\n",
    "        predictions_prob = self.model.predict_proba(X_new)\n",
    "\n",
    "        return predictions_prob\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Apply pipeline to obtain discrete predictions for input data.\n",
    "        \"\"\"\n",
    "        # Your code here: (￣▽￣)/♫•*¨*•.¸¸♪\n",
    "\n",
    "        #PCA\n",
    "        if self.use_PCA == True:\n",
    "            X = self.pca.transform(X)\n",
    "  \n",
    "        \n",
    "\n",
    "        #RFF\n",
    "        #let's generate new features\n",
    "        X_new = expit(X.dot(self.w) + self.b)\n",
    "\n",
    "\n",
    "\n",
    "        #PREDICTIONS\n",
    "        predictions = self.model.predict(X_new)\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0IT5_XaxbArW",
    "outputId": "9881cc17-cfa7-4667-978d-4fadba905c2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA + RFF(expit) + Logreg: accuracy = 0.8118, time = 25.31907296180725\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import time \n",
    "\n",
    "#PCA + RFF + Logreg\n",
    "start = time.time()\n",
    "rff = RFFPipeline() \n",
    "rff = rff.fit(x_train, y_train)\n",
    "y_pred = rff.predict(x_test)\n",
    "acc1 = accuracy_score(y_test, y_pred)\n",
    "end = time.time() - start \n",
    "print(f'PCA + RFF(expit) + Logreg: accuracy = {acc1}, time = {end}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "JIhRbvV3nkAI"
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "class RFFPipeline(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_features=1000, new_dim=50, use_PCA=True, classifier='logreg'):\n",
    "        \"\"\"        \n",
    "        Implements pipeline, which consists of PCA decomposition,\n",
    "        Random Fourier Features approximation and linear classification model.\n",
    "        \n",
    "        n_features, int: amount of synthetic random features generated with RFF approximation.\n",
    "\n",
    "        new_dim, int: PCA output size.\n",
    "        \n",
    "        use_PCA, bool: whether to include PCA preprocessing.\n",
    "        \n",
    "        classifier, string: either 'svm' or 'logreg', a linear classification model to use on top of pipeline.\n",
    "        \n",
    "        Feel free to edit this template for your preferences.    \n",
    "        \"\"\"\n",
    "        self.n_features = n_features\n",
    "        self.use_PCA = use_PCA\n",
    "        self.new_dim = new_dim\n",
    "        self.classifier = classifier\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit all parts of algorithm (PCA, RFF, Classification) to training set.\n",
    "        \"\"\"\n",
    "        # Your code here: (￣▽￣)/♫•*¨*•.¸¸♪\n",
    "\n",
    "        #PCA\n",
    "        if self.use_PCA == True:\n",
    "            self.pca = PCA(n_components=self.new_dim)\n",
    "            X = self.pca.fit_transform(X)\n",
    "  \n",
    "        \n",
    "\n",
    "        #RFF\n",
    "        #let's find sigma\n",
    "        id1 = np.random.randint(X.shape[0], size=1000000)\n",
    "        id2 = np.random.randint(X.shape[0], size=1000000)\n",
    "        sigma = np.sqrt(np.median(np.sum((X[id1] - X[id2])**2, axis = 1)))\n",
    "\n",
    "        #let's generate w and b\n",
    "        np.random.seed(0)\n",
    "        self.w = np.random.normal(0, 1/sigma, size = (X.shape[1], self.n_features))\n",
    "        self.b = np.random.uniform(-math.pi, math.pi, size = (self.n_features))\n",
    "\n",
    "        #let's generate new features\n",
    "        X_new = np.sin(X.dot(self.w) + self.b)\n",
    "\n",
    "\n",
    "        \n",
    "        #MODEL\n",
    "        if self.classifier == 'logreg':\n",
    "            self.model = LogisticRegression(random_state=0).fit(X_new, y)\n",
    "\n",
    "        elif self.classifier == 'svm':\n",
    "            self.model = LinearSVC(random_state=0).fit(X_new, y)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Apply pipeline to obtain scores for input data.\n",
    "        \"\"\"\n",
    "        # Your code here: (￣▽￣)/♫•*¨*•.¸¸♪\n",
    "\n",
    "        #PCA\n",
    "        if self.use_PCA == True:\n",
    "            X = self.pca.transform(X)\n",
    "  \n",
    "        \n",
    "\n",
    "        #RFF\n",
    "        #let's generate new features\n",
    "        X_new = np.sin(X.dot(self.w) + self.b)\n",
    "\n",
    "\n",
    "\n",
    "        #PREDICTIONS\n",
    "        predictions_prob = self.model.predict_proba(X_new)\n",
    "\n",
    "        return predictions_prob\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Apply pipeline to obtain discrete predictions for input data.\n",
    "        \"\"\"\n",
    "        # Your code here: (￣▽￣)/♫•*¨*•.¸¸♪\n",
    "\n",
    "        #PCA\n",
    "        if self.use_PCA == True:\n",
    "            X = self.pca.transform(X)\n",
    "  \n",
    "        \n",
    "\n",
    "        #RFF\n",
    "        #let's generate new features\n",
    "        X_new = np.sin(X.dot(self.w) + self.b)\n",
    "\n",
    "\n",
    "\n",
    "        #PREDICTIONS\n",
    "        predictions = self.model.predict(X_new)\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0IT5_XaxbArW",
    "outputId": "9881cc17-cfa7-4667-978d-4fadba905c2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA + RFF(sin) + Logreg: accuracy = 0.8574, time = 25.610130786895752\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import time \n",
    "\n",
    "#PCA + RFF + Logreg\n",
    "start = time.time()\n",
    "rff = RFFPipeline() \n",
    "rff = rff.fit(x_train, y_train)\n",
    "y_pred = rff.predict(x_test)\n",
    "acc1 = accuracy_score(y_test, y_pred)\n",
    "end = time.time() - start \n",
    "print(f'PCA + RFF(sin) + Logreg: accuracy = {acc1}, time = {end}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "JIhRbvV3nkAI"
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "class RFFPipeline(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_features=1000, new_dim=50, use_PCA=True, classifier='logreg'):\n",
    "        \"\"\"        \n",
    "        Implements pipeline, which consists of PCA decomposition,\n",
    "        Random Fourier Features approximation and linear classification model.\n",
    "        \n",
    "        n_features, int: amount of synthetic random features generated with RFF approximation.\n",
    "\n",
    "        new_dim, int: PCA output size.\n",
    "        \n",
    "        use_PCA, bool: whether to include PCA preprocessing.\n",
    "        \n",
    "        classifier, string: either 'svm' or 'logreg', a linear classification model to use on top of pipeline.\n",
    "        \n",
    "        Feel free to edit this template for your preferences.    \n",
    "        \"\"\"\n",
    "        self.n_features = n_features\n",
    "        self.use_PCA = use_PCA\n",
    "        self.new_dim = new_dim\n",
    "        self.classifier = classifier\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit all parts of algorithm (PCA, RFF, Classification) to training set.\n",
    "        \"\"\"\n",
    "        # Your code here: (￣▽￣)/♫•*¨*•.¸¸♪\n",
    "\n",
    "        #PCA\n",
    "        if self.use_PCA == True:\n",
    "            self.pca = PCA(n_components=self.new_dim)\n",
    "            X = self.pca.fit_transform(X)\n",
    "  \n",
    "        \n",
    "\n",
    "        #RFF\n",
    "        #let's find sigma\n",
    "        id1 = np.random.randint(X.shape[0], size=1000000)\n",
    "        id2 = np.random.randint(X.shape[0], size=1000000)\n",
    "        sigma = np.sqrt(np.median(np.sum((X[id1] - X[id2])**2, axis = 1)))\n",
    "\n",
    "        #let's generate w and b\n",
    "        np.random.seed(0)\n",
    "        self.w = np.random.normal(0, 1/sigma, size = (X.shape[1], self.n_features))\n",
    "        self.b = np.random.uniform(-math.pi, math.pi, size = (self.n_features))\n",
    "\n",
    "        #let's generate new features\n",
    "        X_new = np.sign(X.dot(self.w) + self.b)\n",
    "\n",
    "\n",
    "        \n",
    "        #MODEL\n",
    "        if self.classifier == 'logreg':\n",
    "            self.model = LogisticRegression(random_state=0).fit(X_new, y)\n",
    "\n",
    "        elif self.classifier == 'svm':\n",
    "            self.model = LinearSVC(random_state=0).fit(X_new, y)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Apply pipeline to obtain scores for input data.\n",
    "        \"\"\"\n",
    "        # Your code here: (￣▽￣)/♫•*¨*•.¸¸♪\n",
    "\n",
    "        #PCA\n",
    "        if self.use_PCA == True:\n",
    "            X = self.pca.transform(X)\n",
    "  \n",
    "        \n",
    "\n",
    "        #RFF\n",
    "        #let's generate new features\n",
    "        X_new = np.sign(X.dot(self.w) + self.b)\n",
    "\n",
    "\n",
    "\n",
    "        #PREDICTIONS\n",
    "        predictions_prob = self.model.predict_proba(X_new)\n",
    "\n",
    "        return predictions_prob\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Apply pipeline to obtain discrete predictions for input data.\n",
    "        \"\"\"\n",
    "        # Your code here: (￣▽￣)/♫•*¨*•.¸¸♪\n",
    "\n",
    "        #PCA\n",
    "        if self.use_PCA == True:\n",
    "            X = self.pca.transform(X)\n",
    "  \n",
    "        \n",
    "\n",
    "        #RFF\n",
    "        #let's generate new features\n",
    "        X_new = np.sign(X.dot(self.w) + self.b)\n",
    "\n",
    "\n",
    "\n",
    "        #PREDICTIONS\n",
    "        predictions = self.model.predict(X_new)\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0IT5_XaxbArW",
    "outputId": "9881cc17-cfa7-4667-978d-4fadba905c2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA + RFF(sign) + Logreg: accuracy = 0.8291, time = 25.42455816268921\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import time \n",
    "\n",
    "#PCA + RFF + Logreg\n",
    "start = time.time()\n",
    "rff = RFFPipeline() \n",
    "rff = rff.fit(x_train, y_train)\n",
    "y_pred = rff.predict(x_test)\n",
    "acc1 = accuracy_score(y_test, y_pred)\n",
    "end = time.time() - start \n",
    "print(f'PCA + RFF(sign) + Logreg: accuracy = {acc1}, time = {end}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, из рассмотренных функций cos дает самое высокое качество среди всех. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Эксперименты с классификатором"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "JIhRbvV3nkAI"
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "class RFFPipeline(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_features=1000, new_dim=50, use_PCA=True, classifier='logreg'):\n",
    "        \"\"\"        \n",
    "        Implements pipeline, which consists of PCA decomposition,\n",
    "        Random Fourier Features approximation and linear classification model.\n",
    "        \n",
    "        n_features, int: amount of synthetic random features generated with RFF approximation.\n",
    "\n",
    "        new_dim, int: PCA output size.\n",
    "        \n",
    "        use_PCA, bool: whether to include PCA preprocessing.\n",
    "        \n",
    "        classifier, string: either 'svm' or 'logreg', a linear classification model to use on top of pipeline.\n",
    "        \n",
    "        Feel free to edit this template for your preferences.    \n",
    "        \"\"\"\n",
    "        self.n_features = n_features\n",
    "        self.use_PCA = use_PCA\n",
    "        self.new_dim = new_dim\n",
    "        self.classifier = classifier\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit all parts of algorithm (PCA, RFF, Classification) to training set.\n",
    "        \"\"\"\n",
    "        # Your code here: (￣▽￣)/♫•*¨*•.¸¸♪\n",
    "\n",
    "        #PCA\n",
    "        if self.use_PCA == True:\n",
    "            self.pca = PCA(n_components=self.new_dim)\n",
    "            X = self.pca.fit_transform(X)\n",
    "  \n",
    "        \n",
    "\n",
    "        #RFF\n",
    "        #let's find sigma\n",
    "        id1 = np.random.randint(X.shape[0], size=1000000)\n",
    "        id2 = np.random.randint(X.shape[0], size=1000000)\n",
    "        sigma = np.sqrt(np.median(np.sum((X[id1] - X[id2])**2, axis = 1)))\n",
    "\n",
    "        #let's generate w and b\n",
    "        np.random.seed(0)\n",
    "        self.w = np.random.normal(0, 1/sigma, size = (X.shape[1], self.n_features))\n",
    "        self.b = np.random.uniform(-math.pi, math.pi, size = (self.n_features))\n",
    "\n",
    "        #let's generate new features\n",
    "        X_new = np.cos(X.dot(self.w) + self.b)\n",
    "\n",
    "\n",
    "        \n",
    "        #MODEL\n",
    "        if self.classifier == 'logreg':\n",
    "            self.model = LogisticRegression(random_state=0).fit(X_new, y)\n",
    "\n",
    "        elif self.classifier == 'svm':\n",
    "            self.model = LinearSVC(random_state=0).fit(X_new, y)\n",
    "            \n",
    "        elif self.classifier == 'dt':\n",
    "            self.model = DecisionTreeClassifier(random_state=0).fit(X_new, y)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Apply pipeline to obtain scores for input data.\n",
    "        \"\"\"\n",
    "        # Your code here: (￣▽￣)/♫•*¨*•.¸¸♪\n",
    "\n",
    "        #PCA\n",
    "        if self.use_PCA == True:\n",
    "            X = self.pca.transform(X)\n",
    "  \n",
    "        \n",
    "\n",
    "        #RFF\n",
    "        #let's generate new features\n",
    "        X_new = np.cos(X.dot(self.w) + self.b)\n",
    "\n",
    "\n",
    "\n",
    "        #PREDICTIONS\n",
    "        predictions_prob = self.model.predict_proba(X_new)\n",
    "\n",
    "        return predictions_prob\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Apply pipeline to obtain discrete predictions for input data.\n",
    "        \"\"\"\n",
    "        # Your code here: (￣▽￣)/♫•*¨*•.¸¸♪\n",
    "\n",
    "        #PCA\n",
    "        if self.use_PCA == True:\n",
    "            X = self.pca.transform(X)\n",
    "  \n",
    "        \n",
    "\n",
    "        #RFF\n",
    "        #let's generate new features\n",
    "        X_new = np.cos(X.dot(self.w) + self.b)\n",
    "\n",
    "\n",
    "\n",
    "        #PREDICTIONS\n",
    "        predictions = self.model.predict(X_new)\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0IT5_XaxbArW",
    "outputId": "9881cc17-cfa7-4667-978d-4fadba905c2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA + RFF(cos) + DecisionTree: accuracy = 0.7709, time = 156.91668581962585\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import time \n",
    "\n",
    "#PCA + RFF + DecisionTree\n",
    "start = time.time()\n",
    "rff = RFFPipeline(n_features=1000, new_dim=50, use_PCA=True, classifier='dt') \n",
    "rff = rff.fit(x_train, y_train)\n",
    "y_pred = rff.predict(x_test)\n",
    "acc1 = accuracy_score(y_test, y_pred)\n",
    "end = time.time() - start \n",
    "print(f'PCA + RFF(cos) + DecisionTree: accuracy = {acc1}, time = {end}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "JIhRbvV3nkAI"
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "class RFFPipeline(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_features=1000, new_dim=50, use_PCA=True, classifier='logreg'):\n",
    "        \"\"\"        \n",
    "        Implements pipeline, which consists of PCA decomposition,\n",
    "        Random Fourier Features approximation and linear classification model.\n",
    "        \n",
    "        n_features, int: amount of synthetic random features generated with RFF approximation.\n",
    "\n",
    "        new_dim, int: PCA output size.\n",
    "        \n",
    "        use_PCA, bool: whether to include PCA preprocessing.\n",
    "        \n",
    "        classifier, string: either 'svm' or 'logreg', a linear classification model to use on top of pipeline.\n",
    "        \n",
    "        Feel free to edit this template for your preferences.    \n",
    "        \"\"\"\n",
    "        self.n_features = n_features\n",
    "        self.use_PCA = use_PCA\n",
    "        self.new_dim = new_dim\n",
    "        self.classifier = classifier\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit all parts of algorithm (PCA, RFF, Classification) to training set.\n",
    "        \"\"\"\n",
    "        # Your code here: (￣▽￣)/♫•*¨*•.¸¸♪\n",
    "\n",
    "        #PCA\n",
    "        if self.use_PCA == True:\n",
    "            self.pca = PCA(n_components=self.new_dim)\n",
    "            X = self.pca.fit_transform(X)\n",
    "  \n",
    "        \n",
    "\n",
    "        #RFF\n",
    "        #let's find sigma\n",
    "        id1 = np.random.randint(X.shape[0], size=1000000)\n",
    "        id2 = np.random.randint(X.shape[0], size=1000000)\n",
    "        sigma = np.sqrt(np.median(np.sum((X[id1] - X[id2])**2, axis = 1)))\n",
    "\n",
    "        #let's generate w and b\n",
    "        np.random.seed(0)\n",
    "        self.w = np.random.normal(0, 1/sigma, size = (X.shape[1], self.n_features))\n",
    "        self.b = np.random.uniform(-math.pi, math.pi, size = (self.n_features))\n",
    "\n",
    "        #let's generate new features\n",
    "        X_new = np.cos(X.dot(self.w) + self.b)\n",
    "\n",
    "\n",
    "        \n",
    "        #MODEL\n",
    "        if self.classifier == 'logreg':\n",
    "            self.model = LogisticRegression(random_state=0).fit(X_new, y)\n",
    "\n",
    "        elif self.classifier == 'svm':\n",
    "            self.model = LinearSVC(random_state=0).fit(X_new, y)\n",
    "            \n",
    "        elif self.classifier == 'knn':\n",
    "            self.model = KNeighborsClassifier().fit(X_new, y)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Apply pipeline to obtain scores for input data.\n",
    "        \"\"\"\n",
    "        # Your code here: (￣▽￣)/♫•*¨*•.¸¸♪\n",
    "\n",
    "        #PCA\n",
    "        if self.use_PCA == True:\n",
    "            X = self.pca.transform(X)\n",
    "  \n",
    "        \n",
    "\n",
    "        #RFF\n",
    "        #let's generate new features\n",
    "        X_new = np.cos(X.dot(self.w) + self.b)\n",
    "\n",
    "\n",
    "\n",
    "        #PREDICTIONS\n",
    "        predictions_prob = self.model.predict_proba(X_new)\n",
    "\n",
    "        return predictions_prob\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Apply pipeline to obtain discrete predictions for input data.\n",
    "        \"\"\"\n",
    "        # Your code here: (￣▽￣)/♫•*¨*•.¸¸♪\n",
    "\n",
    "        #PCA\n",
    "        if self.use_PCA == True:\n",
    "            X = self.pca.transform(X)\n",
    "  \n",
    "        \n",
    "\n",
    "        #RFF\n",
    "        #let's generate new features\n",
    "        X_new = np.cos(X.dot(self.w) + self.b)\n",
    "\n",
    "\n",
    "\n",
    "        #PREDICTIONS\n",
    "        predictions = self.model.predict(X_new)\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0IT5_XaxbArW",
    "outputId": "9881cc17-cfa7-4667-978d-4fadba905c2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA + RFF(cos) + KNN: accuracy = 0.8567, time = 28.117629289627075\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import time \n",
    "\n",
    "#PCA + RFF + KNN\n",
    "start = time.time()\n",
    "rff = RFFPipeline(n_features=1000, new_dim=50, use_PCA=True, classifier='knn') \n",
    "rff = rff.fit(x_train, y_train)\n",
    "y_pred = rff.predict(x_test)\n",
    "acc1 = accuracy_score(y_test, y_pred)\n",
    "end = time.time() - start \n",
    "print(f'PCA + RFF(cos) + KNN: accuracy = {acc1}, time = {end}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "JIhRbvV3nkAI"
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "class RFFPipeline(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_features=1000, new_dim=50, use_PCA=True, classifier='logreg'):\n",
    "        \"\"\"        \n",
    "        Implements pipeline, which consists of PCA decomposition,\n",
    "        Random Fourier Features approximation and linear classification model.\n",
    "        \n",
    "        n_features, int: amount of synthetic random features generated with RFF approximation.\n",
    "\n",
    "        new_dim, int: PCA output size.\n",
    "        \n",
    "        use_PCA, bool: whether to include PCA preprocessing.\n",
    "        \n",
    "        classifier, string: either 'svm' or 'logreg', a linear classification model to use on top of pipeline.\n",
    "        \n",
    "        Feel free to edit this template for your preferences.    \n",
    "        \"\"\"\n",
    "        self.n_features = n_features\n",
    "        self.use_PCA = use_PCA\n",
    "        self.new_dim = new_dim\n",
    "        self.classifier = classifier\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit all parts of algorithm (PCA, RFF, Classification) to training set.\n",
    "        \"\"\"\n",
    "        # Your code here: (￣▽￣)/♫•*¨*•.¸¸♪\n",
    "\n",
    "        #PCA\n",
    "        if self.use_PCA == True:\n",
    "            self.pca = PCA(n_components=self.new_dim)\n",
    "            X = self.pca.fit_transform(X)\n",
    "  \n",
    "        \n",
    "\n",
    "        #RFF\n",
    "        #let's find sigma\n",
    "        id1 = np.random.randint(X.shape[0], size=1000000)\n",
    "        id2 = np.random.randint(X.shape[0], size=1000000)\n",
    "        sigma = np.sqrt(np.median(np.sum((X[id1] - X[id2])**2, axis = 1)))\n",
    "\n",
    "        #let's generate w and b\n",
    "        np.random.seed(0)\n",
    "        self.w = np.random.normal(0, 1/sigma, size = (X.shape[1], self.n_features))\n",
    "        self.b = np.random.uniform(-math.pi, math.pi, size = (self.n_features))\n",
    "\n",
    "        #let's generate new features\n",
    "        X_new = np.cos(X.dot(self.w) + self.b)\n",
    "\n",
    "\n",
    "        \n",
    "        #MODEL\n",
    "        if self.classifier == 'logreg':\n",
    "            self.model = LogisticRegression(random_state=0).fit(X_new, y)\n",
    "\n",
    "        elif self.classifier == 'svm':\n",
    "            self.model = LinearSVC(random_state=0).fit(X_new, y)\n",
    "            \n",
    "        elif self.classifier == 'randomforest':\n",
    "            self.model = RandomForestClassifier(random_state=0).fit(X_new, y)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Apply pipeline to obtain scores for input data.\n",
    "        \"\"\"\n",
    "        # Your code here: (￣▽￣)/♫•*¨*•.¸¸♪\n",
    "\n",
    "        #PCA\n",
    "        if self.use_PCA == True:\n",
    "            X = self.pca.transform(X)\n",
    "  \n",
    "        \n",
    "\n",
    "        #RFF\n",
    "        #let's generate new features\n",
    "        X_new = np.cos(X.dot(self.w) + self.b)\n",
    "\n",
    "\n",
    "\n",
    "        #PREDICTIONS\n",
    "        predictions_prob = self.model.predict_proba(X_new)\n",
    "\n",
    "        return predictions_prob\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Apply pipeline to obtain discrete predictions for input data.\n",
    "        \"\"\"\n",
    "        # Your code here: (￣▽￣)/♫•*¨*•.¸¸♪\n",
    "\n",
    "        #PCA\n",
    "        if self.use_PCA == True:\n",
    "            X = self.pca.transform(X)\n",
    "  \n",
    "        \n",
    "\n",
    "        #RFF\n",
    "        #let's generate new features\n",
    "        X_new = np.cos(X.dot(self.w) + self.b)\n",
    "\n",
    "\n",
    "\n",
    "        #PREDICTIONS\n",
    "        predictions = self.model.predict(X_new)\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0IT5_XaxbArW",
    "outputId": "9881cc17-cfa7-4667-978d-4fadba905c2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA + RFF(cos) + RandomForest: accuracy = 0.8627, time = 219.48713898658752\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import time \n",
    "\n",
    "#PCA + RFF + RandomForest\n",
    "start = time.time()\n",
    "rff = RFFPipeline(n_features=1000, new_dim=50, use_PCA=True, classifier='randomforest') \n",
    "rff = rff.fit(x_train, y_train)\n",
    "y_pred = rff.predict(x_test)\n",
    "acc1 = accuracy_score(y_test, y_pred)\n",
    "end = time.time() - start \n",
    "print(f'PCA + RFF(cos) + RandomForest: accuracy = {acc1}, time = {end}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значит, самый близкий к качеству linear SVM и Logreg классификатор KNN, однако и он оказывается ниже по качеству, чем названные выше модели. В повышении качества помогают более сложные модели, ансамбли, например, RandomForest дал результат выше логистической регрессии, но оказался горадо более времязатратным, однако в сравнении с SVM качество все равно оказалось ниже. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
